// PRACTICAL SCALABILITY TEST FOR QUANT COMMANDER
// Real-world performance testing with current implementation

import { FlexibleTopNData, TopNAnalysisParams } from '../analyzers/topNTypes';
import { classifyDatasetSize, estimateMemoryUsage } from '../analysis/scalabilityAssessment';

/**
 * Generate realistic test dataset with controlled size
 * Simulates real business data patterns
 */
function generateRealisticDataset(size: number): FlexibleTopNData[] {
  const regions = ['North America', 'Europe', 'Asia Pacific', 'South America', 'Middle East', 'Africa'];
  const products = ['Enterprise Software', 'Cloud Services', 'Consulting', 'Hardware', 'Support', 'Training'];
  const salespeople = Array.from({length: Math.min(size / 50, 200)}, (_, i) => `Rep ${i + 1}`);
  
  console.log(`üîß Generating ${size.toLocaleString()} realistic business records...`);
  
  const data: FlexibleTopNData[] = [];
  
  for (let i = 0; i < size; i++) {
    // Create realistic business patterns
    const regionIdx = Math.floor(Math.random() * regions.length);
    const productIdx = Math.floor(Math.random() * products.length);
    const repIdx = Math.floor(Math.random() * salespeople.length);
    
    // Realistic seasonal and regional variations
    const month = Math.floor(Math.random() * 12) + 1;
    const regionMultiplier = [1.2, 1.0, 0.9, 0.7, 0.8, 0.6][regionIdx];
    const seasonalMultiplier = month <= 3 ? 0.8 : month >= 10 ? 1.3 : 1.0;
    
    const baseSales = 25000 + Math.random() * 200000;
    const sales = Math.round(baseSales * regionMultiplier * seasonalMultiplier);
    
    data.push({
      id: i + 1,
      region: regions[regionIdx],
      product: products[productIdx],
      salesperson: salespeople[repIdx],
      sales: sales,
      units: Math.round(sales / (500 + Math.random() * 1000)),
      date: `2024-${month.toString().padStart(2, '0')}-${Math.floor(Math.random() * 28) + 1}`,
      quarter: `2024-Q${Math.ceil(month / 3)}`,
      territory: `Territory ${Math.floor(Math.random() * 20) + 1}`,
      customer_segment: ['Enterprise', 'SMB', 'Startup'][Math.floor(Math.random() * 3)]
    });
  }
  
  return data;
}

/**
 * Simulate Top N analysis performance without full implementation
 * Tests the core bottlenecks: filtering, grouping, sorting
 */
function simulateTopNPerformance(data: FlexibleTopNData[], params: TopNAnalysisParams) {
  console.log(`üìä Simulating Top N analysis on ${data.length.toLocaleString()} records...`);
  
  const startTime = performance.now();
  
  // STEP 1: Data validation and preprocessing (O(n))
  const preprocessStart = performance.now();
  const validData = data.filter(row => {
    const value = row[params.valueColumn];
    const numValue = typeof value === 'number' ? value : parseFloat(String(value));
    return !isNaN(numValue) && (params.categoryColumn ? row[params.categoryColumn] : true);
  });
  const preprocessTime = performance.now() - preprocessStart;
  
  // STEP 2: Aggregation (O(n) with Map)
  const aggregationStart = performance.now();
  const categoryMap = new Map<string, { sum: number; count: number }>();
  
  validData.forEach(row => {
    const category = params.categoryColumn ? String(row[params.categoryColumn]) : 'All Data';
    const value = typeof row[params.valueColumn] === 'number' 
      ? row[params.valueColumn] as number
      : parseFloat(String(row[params.valueColumn]));
    
    const existing = categoryMap.get(category);
    if (existing) {
      existing.sum += value;
      existing.count += 1;
    } else {
      categoryMap.set(category, { sum: value, count: 1 });
    }
  });
  const aggregationTime = performance.now() - aggregationStart;
  
  // STEP 3: Sorting (O(k log k) where k = categories)
  const sortingStart = performance.now();
  const categories = Array.from(categoryMap.entries()).map(([category, data]) => ({
    category,
    total: data.sum,
    average: data.sum / data.count,
    count: data.count
  }));
  
  categories.sort((a, b) => b.total - a.total);
  const sortingTime = performance.now() - sortingStart;
  
  // STEP 4: Extract results
  const extractionStart = performance.now();
  const topN = categories.slice(0, params.n);
  const bottomN = categories.slice(-params.n).reverse();
  const extractionTime = performance.now() - extractionStart;
  
  const totalTime = performance.now() - startTime;
  
  // Performance metrics
  const throughput = data.length / (totalTime / 1000);
  const categoriesProcessed = categoryMap.size;
  
  return {
    performance: {
      totalTime,
      preprocessTime,
      aggregationTime,
      sortingTime,
      extractionTime,
      throughput
    },
    results: {
      topN,
      bottomN,
      totalRecords: data.length,
      validRecords: validData.length,
      categoriesProcessed
    }
  };
}

/**
 * Run comprehensive scalability test
 */
export function runScalabilityTest() {
  console.log('üéØ QUANT COMMANDER - COMPREHENSIVE SCALABILITY TEST');
  console.log('==================================================\n');
  
  const testSizes = [1000, 5000, 10000, 25000, 50000, 100000];
  const results: Array<{
    size: number;
    classification: string;
    totalTime: number;
    throughput: number;
    memoryEstimate: string;
  }> = [];
  
  testSizes.forEach(size => {
    console.log(`\nüìä Testing ${size.toLocaleString()} records:`);
    console.log('‚îÄ'.repeat(40));
    
    try {
      // Generate test data
      const dataGenStart = performance.now();
      const testData = generateRealisticDataset(size);
      const dataGenTime = performance.now() - dataGenStart;
      
      // Classify dataset
      const classification = classifyDatasetSize(size);
      const memoryEstimate = estimateMemoryUsage(size, 10);
      
      console.log(`üìà Dataset classification: ${classification.category.toUpperCase()}`);
      console.log(`‚ö†Ô∏è  Risk level: ${classification.riskLevel.toUpperCase()}`);
      console.log(`üíæ Estimated memory: ${memoryEstimate.peakMemory}`);
      console.log(`‚è±Ô∏è  Data generation: ${dataGenTime.toFixed(0)}ms`);
      
      // Test Top N analysis performance
      const analysisResult = simulateTopNPerformance(testData, {
        n: 10,
        analysisScope: 'total',
        valueColumn: 'sales',
        categoryColumn: 'region',
        direction: 'both'
      });
      
      // Report results
      const perf = analysisResult.performance;
      console.log(`\n‚úÖ PERFORMANCE RESULTS:`);
      console.log(`   Total time: ${perf.totalTime.toFixed(0)}ms`);
      console.log(`   Throughput: ${perf.throughput.toLocaleString()} records/second`);
      console.log(`   Preprocessing: ${perf.preprocessTime.toFixed(0)}ms`);
      console.log(`   Aggregation: ${perf.aggregationTime.toFixed(0)}ms`);
      console.log(`   Sorting: ${perf.sortingTime.toFixed(0)}ms`);
      console.log(`   Categories: ${analysisResult.results.categoriesProcessed}`);
      
      // Performance assessment
      if (perf.totalTime < 100) {
        console.log(`   üü¢ EXCELLENT - Sub-100ms performance`);
      } else if (perf.totalTime < 1000) {
        console.log(`   üü° GOOD - Under 1 second`);
      } else if (perf.totalTime < 5000) {
        console.log(`   üü† ACCEPTABLE - Under 5 seconds`);
      } else {
        console.log(`   üî¥ SLOW - Consider optimization`);
      }
      
      results.push({
        size,
        classification: classification.category,
        totalTime: perf.totalTime,
        throughput: perf.throughput,
        memoryEstimate: memoryEstimate.peakMemory
      });
      
    } catch (error) {
      console.log(`‚ùå FAILED: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  });
  
  // Summary report
  console.log('\n' + '='.repeat(60));
  console.log('üìã SCALABILITY SUMMARY REPORT');
  console.log('='.repeat(60));
  
  results.forEach(result => {
    const speed = result.totalTime < 100 ? 'üü¢' : result.totalTime < 1000 ? 'üü°' : result.totalTime < 5000 ? 'üü†' : 'üî¥';
    console.log(`${speed} ${result.size.toString().padStart(6)} rows: ${result.totalTime.toFixed(0).padStart(6)}ms (${result.throughput.toLocaleString().padStart(8)} rec/sec) [${result.classification}]`);
  });
  
  // Million row projection
  console.log('\nüéØ 1M ROW PROJECTION:');
  if (results.length >= 3) {
    const avgThroughput = results.slice(-3).reduce((sum, r) => sum + r.throughput, 0) / 3;
    const projectedTime = 1000000 / avgThroughput;
    
    console.log(`   Estimated time: ${(projectedTime).toFixed(1)} seconds`);
    console.log(`   Memory estimate: ~2-3GB`);
    
    if (projectedTime < 10) {
      console.log(`   ‚úÖ VERDICT: 1M rows should work with current implementation`);
    } else if (projectedTime < 30) {
      console.log(`   ‚ö†Ô∏è  VERDICT: 1M rows possible but slow - optimization recommended`);
    } else {
      console.log(`   ‚ùå VERDICT: 1M rows too slow - architectural changes needed`);
    }
  }
  
  console.log('\nüí° RECOMMENDATIONS:');
  console.log('   - Current implementation optimal for <100K rows');
  console.log('   - Add progress indicators for operations >1 second');
  console.log('   - Consider streaming for 500K+ rows');
  console.log('   - Server-side processing recommended for 1M+ rows');
  
  return results;
}

// Export for easy testing
export { generateRealisticDataset, simulateTopNPerformance };
